---
title: "TD4 ANALYSE DE LA NON-STATIONARITE ET RACINES UNITAIRES"
author: "CROCHET Florian et MARTERET Achille"
format: pdf
toc: true
toc-title: Sommaire
---

\newpage
# Importation des libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(openxlsx)
library(urca)
library(forecast)
library(tseries)
```



\newpage
# Chocs permanents vs. chocs transitoires : une analyse exploratoire

```{r}
simulate_ar1 <- function(phi, choc_value, choc_time = 100, n = 200) {
  Y <- numeric(n)
  eps <- rnorm(n, mean = 0, sd = 1)
  
  for (t in 2:n) {
    Y[t] <- phi * Y[t - 1] + eps[t]
    if (t == choc_time) {
      Y[t] <- Y[t] + choc_value
    }
  }
  return(Y)
}

set.seed(132)

phi_vals <- c(0.5, 0.9, 1.0)
chocs <- c(20, 40, -20, -40)

# Stocker les r√©sultats dans une data.frame
results <- data.frame()

for (choc in chocs) {
  for (phi in phi_vals) {
    serie <- simulate_ar1(phi, choc)
    df <- data.frame(
      t = 1:200,
      Y = serie,
      phi = paste0("phi = ", phi),
      choc = paste0("Choc = ", choc)
    )
    results <- rbind(results, df)
  }
}
ggplot(results, aes(x = t, y = Y, color = phi)) +
  geom_line() +
  facet_wrap(~choc, scales = "free_y") +
  labs(title = "Impact de chocs √† t=100 pour diff√©rentes valeurs de œï‚ÇÅ",
       x = "Temps", y = "Y_t") +
  theme_minimal() +
  theme(legend.position = "top")


simulate_ar1 <- function(phi, choc_value, choc_time = 100, n = 200) {
  Y <- numeric(n)
  eps <- rnorm(n, mean = 0, sd = 1)
  
  for (t in 2:n) {
    Y[t] <- phi * Y[t - 1] + eps[t]
    if (t == choc_time) {
      Y[t] <- Y[t] + choc_value
    }
  }
  return(Y)
}
```

Les processus avec $œï = 1$ ne retombe pas sur la tendance ce qui confirme la marche al√©atoire.

Pour $œï=0.5$, le choc dispara√Æt rapidement. Pour $œï=0.9$, il persiste plus longtemps. Pour $œï=1.0$, il devient permanent.

Dans le cadre d'une marche al√©atoire le choc √† un impacte permanent et al√©atoire sur les diff√©rents processus, tandis que pour les phi < 1, les processus reviennent √† leur niveau de tendance initial.



\newpage
# TS vs. DS : simulation de processus

```{r}
set.seed(246)

T <- 200  # Echantillon de 1000 observations

# Processus stochastique
Y_TS <- numeric(T)
Y_DS <- numeric(T)
```

## Loi normale centr√©e de variance 1/4

### Mise √† jour des param√®tres

```{r}
sigma1 <- 1/4

epsilon1 <- rnorm(T, mean = 0, sd = sqrt(sigma1))  # ~ N(0,1/4)
```

### Simulation des processus

```{r}
# Premier processus

for (t in 1:T) {
  Y_TS[t] <- 0.2 * t + epsilon1[t]
}


# Second processus

for (t in 2:T) {
  Y_DS[t] <- 0.2 + Y_DS[t - 1] + epsilon1[t]
}
```

### Repr√©sentation graphique

```{r}
# Base de donn√©es
data <- tibble(
  Temps = rep(seq_len(T), times = 2),
  Valeur = c(Y_TS, Y_DS),
  Processus = rep(c("TS: Y[t] = 0.2t + Œµ[t]", "DS: Y[t] = 0.2 + Y[t-1] + Œµ[t]"), each = T)
)


# Graphique
data |> 
  ggplot() +
  aes(x = Temps, y = Valeur, color = Processus) +
  geom_line() +
  labs(title = "Comparaison entre un processus d√©terministe et un processus stochastique",
       x = "Temps",
       y = "Valeur de la s√©rie") +
  theme_bw()
```

La s√©rie TS est stationnaire autour d‚Äôune tendance d√©terministe (une tendance lin√©aire de pente 10/50=0.2). Les chocs $ùúÄ_t$ n'ont pas d'effet permanent sur la s√©rie : apr√®s un choc, la s√©rie revient √† sa tendance.

La s√©rie DS contient une racine unitaire. Un choc $ùúÄ_t$ a un effet permanent : la s√©rie ne revient pas √† une tendance fixe apr√®s un choc.

\newpage
## Loi normale centr√©e de variance 1/2

### Mise √† jour des param√®tres

```{r}
sigma2 <- 1/2

epsilon2 <- rnorm(T, mean = 0, sd = sqrt(sigma2))  # ~ N(0,1/2)
```

### Simulation des processus

```{r}
# Premier processus

for (t in 1:T) {
  Y_TS[t] <- 0.2 * t + epsilon2[t]
}


# Second processus

for (t in 2:T) {
  Y_DS[t] <- 0.2 + Y_DS[t - 1] + epsilon2[t]
}
```

### Repr√©sentation graphique

```{r}
# Base de donn√©es
data <- tibble(
  Temps = rep(seq_len(T), times = 2),
  Valeur = c(Y_TS, Y_DS),
  Processus = rep(c("TS: Y[t] = 0.2t + Œµ[t]", "DS: Y[t] = 0.2 + Y[t-1] + Œµ[t]"), each = T)
)


# Graphique
data |> 
  ggplot() +
  aes(x = Temps, y = Valeur, color = Processus) +
  geom_line() +
  labs(title = "Comparaison entre un processus d√©terministe et un processus stochastique",
       x = "Temps",
       y = "Valeur de la s√©rie") +
  theme_bw()
```

La s√©rie TS est stationnaire autour d‚Äôune tendance d√©terministe (une tendance lin√©aire de pente 10/50=0.2). Les chocs $ùúÄ_t$ n'ont pas d'effet permanent sur la s√©rie : apr√®s un choc, la s√©rie revient √† sa tendance.

La s√©rie DS contient une racine unitaire. Un choc $ùúÄ_t$ a un effet permanent : la s√©rie ne revient pas √† une tendance fixe apr√®s un choc.

En augmentant la variance des r√©sidus de 1/4 √† 1/2, nous avons accru l'impact des chocs. Nous observons ainsi que les variations des deux s√©ries sont plus importantes.

\newpage
## Loi normale centr√©e r√©duite

### Mise √† jour des param√®tres

```{r}
sigma3 <- 1

epsilon3 <- rnorm(T, mean = 0, sd = sqrt(sigma3))  # ~ N(0,1)
```

### Simulation des processus

```{r}
# Premier processus

for (t in 1:T) {
  Y_TS[t] <- 0.2 * t + epsilon3[t]
}


# Second processus

for (t in 2:T) {
  Y_DS[t] <- 0.2 + Y_DS[t - 1] + epsilon3[t]
}
```

### Repr√©sentation graphique

```{r}
# Base de donn√©es
data <- tibble(
  Temps = rep(seq_len(T), times = 2),
  Valeur = c(Y_TS, Y_DS),
  Processus = rep(c("TS: Y[t] = 0.2t + Œµ[t]", "DS: Y[t] = 0.2 + Y[t-1] + Œµ[t]"), each = T)
)


# Graphique
data |> 
  ggplot() +
  aes(x = Temps, y = Valeur, color = Processus) +
  geom_line() +
  labs(title = "Comparaison entre un processus d√©terministe et un processus stochastique",
       x = "Temps",
       y = "Valeur de la s√©rie") +
  theme_bw()
```

La s√©rie TS est stationnaire autour d‚Äôune tendance d√©terministe (une tendance lin√©aire de pente 10/50=0.2). Les chocs $ùúÄ_t$ n'ont pas d'effet permanent sur la s√©rie : apr√®s un choc, la s√©rie revient √† sa tendance.

La s√©rie DS contient une racine unitaire. Un choc $ùúÄ_t$ a un effet permanent : la s√©rie ne revient pas √† une tendance fixe apr√®s un choc.

En augmentant la variance des r√©sidus 1/2 √† 1, nous avons accru l'impact des chocs. Nous observons ainsi que les variations des deux s√©ries sont plus importantes.



\newpage
# R√©gressions fallacieuses

## G√©n√©ration de 5000 s√©ries pour 200 observations chacune

```{r}
set.seed(123)

# Param√®tres
n_series <- 5000
n_obs <- 200
alpha <- 0.05

# Fonction pour g√©n√©rer une marche al√©atoire
marche_aleatoire <- function(n) {
  cumsum(rnorm(n))
}

# Stockage des p-values
p_values <- numeric(n_series)

# Boucle pour g√©n√©rer les s√©ries et effectuer les r√©gressions
for (i in 1:n_series) {
  Xt <- marche_aleatoire(n_obs)
  Yt <- marche_aleatoire(n_obs)
  
  model <- lm(Yt ~ Xt)
  p_values[i] <- summary(model)$coefficients[2, 4] # p-value associ√©e √† Œ≤1
}

# Pourcentage de rejets de H0
rejection_rate <- mean(p_values < alpha) * 100

cat("Pourcentage de rejets de H0 au seuil de 5%:", rejection_rate, "%\n")
```

Nos deux processus {Xt} et {Yt} g√©n√©r√©s artificiellement comme deux marches al√©atoires ind√©pendantes, devrait √™tre ind√©pendantes, il ne devrait pas y avoir de corr√©lation entre les deux s√©ries. Ainsi, si on estime Yt = Œ≤0 +Œ≤1Xt +Œ∑t, Œ≤1 devrait √™tre diff√©rent de 0 que dans 5% des cas. Or, on remarque dans nos s√©ries que l'hypoth√®se H0 : Œ≤1 = 0 au taux d'erreur de 5%, obtient un pourcentage de rejet de 83.52% pour 200 observations et 5000 s√©ries test√©s.


\newpage
## G√©n√©ration de 5000 s√©ries pour 400 observations chacune

```{r}
set.seed(123)

# Param√®tres
n_series <- 5000
n_obs <- 400      # Nous passons de 200 √† 400 observations.
alpha <- 0.05

# Fonction pour g√©n√©rer une marche al√©atoire
marche_aleatoire <- function(n) {
  cumsum(rnorm(n))
}

# Stockage des p-values
p_values <- numeric(n_series)

# Boucle pour g√©n√©rer les s√©ries et effectuer les r√©gressions
for (i in 1:n_series) {
  Xt <- marche_aleatoire(n_obs)
  Yt <- marche_aleatoire(n_obs)
  
  model <- lm(Yt ~ Xt)
  p_values[i] <- summary(model)$coefficients[2, 4] # p-value associ√©e √† Œ≤1
}

# Pourcentage de rejets de H0
rejection_rate <- mean(p_values < alpha) * 100

cat("Pourcentage de rejets de H0 au seuil de 5%:", rejection_rate, "%\n")
```

Lorsqu'on augmente le nombre d'observations le pourcentage de rejet augmente. Pour 400 observations le pourcentage de rejet passe de 83.52% √† 88.16%


\newpage
## G√©n√©ration de 8000 s√©ries pour 200 observations chacune

```{r}
set.seed(123)

# Param√®tres
n_series <- 8000 # Nous passons de 5000 √† 8000 observations.
n_obs <- 200
alpha <- 0.05

# Fonction pour g√©n√©rer une marche al√©atoire
marche_aleatoire <- function(n) {
  cumsum(rnorm(n))
}

# Stockage des p-values
p_values <- numeric(n_series)

# Boucle pour g√©n√©rer les s√©ries et effectuer les r√©gressions
for (i in 1:n_series) {
  Xt <- marche_aleatoire(n_obs)
  Yt <- marche_aleatoire(n_obs)
  
  model <- lm(Yt ~ Xt)
  p_values[i] <- summary(model)$coefficients[2, 4] # p-value associ√©e √† Œ≤1
}

# Pourcentage de rejets de H0
rejection_rate <- mean(p_values < alpha) * 100

cat("Pourcentage de rejets de H0 au seuil de 5%:", rejection_rate, "%\n")
```

Lorsqu'on augmente le nombre de s√©ries g√©n√©r√©es, passant de 5000 √† 8000, le pourcentage de rejets au seuil de 5% diminue l√©g√®rement, passant √† 82.9875%.

Les r√©sultats d√©pendent donc plus fortement du nombre d'observation g√©n√©r√©e, que du nombre de s√©rie g√©n√©r√©e.


\newpage
## Conclusion

Les r√©sultats montrent qu‚Äôen pr√©sence de marches al√©atoires, la r√©gression produit un taux de rejet de H0 bien sup√©rieur aux 5% attendus sous l‚Äôhypoth√®se nulle, ce qui illustre une corr√©lation fallacieuse.

Lorsque le nombre d‚Äôobservations par s√©rie augmente, le taux de rejet s‚Äôaccro√Æt (de 83,52% √† 88,16% pour 200 √† 400 observations), ce qui sugg√®re que la d√©pendance temporelle accrue amplifie la fausse corr√©lation.

En revanche, l‚Äôaugmentation du nombre de s√©ries simul√©es ne modifie pas significativement le ph√©nom√®ne (82,99% pour 8000 s√©ries contre 83,52% pour 5000), confirmant que le biais provient de la structure des donn√©es et non du nombre de simulations.



\newpage
# Distribution de la statistique de test de Dickey-Fuller pour le mod√®le sans constante ni tendance via la m√©thode de Monte Carlo

## Processus √† racine unitaire

```{r}
set.seed(246)

# Param√®tres
nb_obs <- 100
nb_sim <- 10000

# Stockage des t-statistiques
t_stats <- numeric(nb_sim)

# Simulation du processus racine unitaire
for (i in 1:nb_sim) {
  
  epsilon <- rnorm(nb_obs, mean = 0, sd = 1)   # R√©sidus normaux centr√©s r√©duits
  Y <- numeric(nb_obs)
  
  Y[1] <- epsilon[1]         # Premi√®re observation
  
  for (t in 2:nb_obs) {
    Y[t] <- Y[t-1] + epsilon[t]  # Processus racine unitaire
  }
  
  # R√©gression de Yt sur Yt-1 pour estimer le param√®tre phi_1 et son √©cart-type
  modele <- lm(Y[2:nb_obs] ~ Y[1:(nb_obs-1)] - 1)
  
  phi_1 <- coef(modele)[1]         # Coefficient estim√© phi_1
  gamma <- phi_1 - 1              # Calcul de gamma estim√©
  
  # Ecart-type de gamma (√©gal √† l'√©cart-type de phi_1)
  se_gamma <- summary(modele)$coefficients[1, 2]
  
  # Statistique de test
  t_stats[i] <- gamma / se_gamma
}

# Estimation de la densit√© par noyau pour visualiser la distribution
densite <- density(t_stats)

# Histogramme avec la courbe de densit√© liss√©e
hist(
  t_stats, 
  breaks = 50, 
  probability = TRUE, 
  col = "lightblue", 
  main = "Distribution des t-statistiques avec lissage par noyau", 
  xlab = "t-stat"
)
lines(
  densite,
  col = "red",
  lwd = 2
)

# Calcul des valeurs critiques pour 10%, 5% et 1%
val_crit_est_10 <- quantile(t_stats, 0.10)
val_crit_est_5  <- quantile(t_stats, 0.05)
val_crit_est_1  <- quantile(t_stats, 0.01)

cat("Valeur critique unilat√©rale √† 10% :", val_crit_est_10, "\n")
cat("Valeur critique unilat√©rale √† 5%  :", val_crit_est_5, "\n")
cat("Valeur critique unilat√©rale √† 1%  :", val_crit_est_1, "\n")


# Valeurs critiques r√©elles pour n = 100 et p = 10%, p = 5% et p = 1%
critical_values <- unitrootTable(trend = "nc", statistic = "t")

val_crit_10 <- critical_values["100", "0.100"]
val_crit_5  <- critical_values["100", "0.050"]
val_crit_1  <- critical_values["100", "0.010"]

# Tableau comparatif
tableau_comparatif <- tibble(
  "Seuil" = c("10%", "5%", "1%"),
  "Valeur critique estim√©e" = c(val_crit_est_10, val_crit_est_5, val_crit_est_1),
  "Valeur critique r√©elle" = c(val_crit_10, val_crit_5, val_crit_1)
)

tableau_comparatif
```

Gr√¢ce √† la m√©thode de Monte Carlo, les valeurs obtenues par simulation d‚Äôun processus √† racine unitaire, sans constante ni tendance, sont quasi identiques √† celles figurant dans la table de Dickey-Fuller. Plus le nombre de simulations est √©lev√©, plus les statistiques obtenues convergent vers celles pr√©sentes dans la table.

\newpage
## Processus avec constante delta_0 = 5

```{r}
set.seed(246)

# Param√®tres
nb_obs <- 100
nb_sim <- 10000

# Stockage des t-statistiques
t_stats <- numeric(nb_sim)

# Simulation du processus avec constante (delta_0 = 5)
delta_0 <- 5
for (i in 1:nb_sim) {
  
  epsilon <- rnorm(nb_obs, mean = 0, sd = 1)   # R√©sidus normaux centr√©s r√©duits
  Y <- numeric(nb_obs)
  
  Y[1] <- delta_0 + epsilon[1]  # Premi√®re observation avec constante
  
  for (t in 2:nb_obs) {
    Y[t] <- delta_0 + Y[t-1] + epsilon[t]  # Processus avec constante
  }
  
  # Cr√©ation de la variable de tendance
  trend <- 1:nb_obs  # Variable temporelle croissante
  
  # pour tester un mod√®le avec constante, il est pr√©f√©rable d‚Äôadopter une sp√©cification
  # avec constante et tendance
  modele <- lm(Y[2:nb_obs] ~ Y[1:(nb_obs-1)] + trend[2:nb_obs])
  
  phi_1 <- coef(modele)[2]         # Coefficient estim√© phi_1 (sur Yt-1)
  gamma <- phi_1 - 1              # Calcul de gamma estim√©
  
  # Ecart-type de gamma (√©gal √† l'√©cart-type de phi_1)
  se_gamma <- summary(modele)$coefficients[2, 2]
  
  # Statistique de test
  t_stats[i] <- gamma / se_gamma
}

# Estimation de la densit√© par noyau pour visualiser la distribution
densite <- density(t_stats)

# Histogramme avec la courbe de densit√© liss√©e
hist(
  t_stats, 
  breaks = 50, 
  probability = TRUE, 
  col = "lightblue", 
  main = "Distribution des t-statistiques avec lissage par noyau", 
  xlab = "t-stat"
)
lines(
  densite,
  col = "red",
  lwd = 2
)

# Calcul des valeurs critiques pour 10%, 5% et 1%
val_crit_est_10 <- quantile(t_stats, 0.10)
val_crit_est_5  <- quantile(t_stats, 0.05)
val_crit_est_1  <- quantile(t_stats, 0.01)

cat("Valeur critique unilat√©rale √† 10% :", val_crit_est_10, "\n")
cat("Valeur critique unilat√©rale √† 5%  :", val_crit_est_5, "\n")
cat("Valeur critique unilat√©rale √† 1%  :", val_crit_est_1, "\n")

# Valeurs critiques r√©elles pour n = 100 et p = 10%, p = 5% et p = 1%
critical_values <- unitrootTable(trend = "ct", statistic = "t")

val_crit_10 <- critical_values["100", "0.100"]
val_crit_5  <- critical_values["100", "0.050"]
val_crit_1  <- critical_values["100", "0.010"]

# Tableau comparatif
tableau_comparatif <- tibble(
  "Seuil" = c("10%", "5%", "1%"),
  "Valeur critique estim√©e" = c(val_crit_est_10, val_crit_est_5, val_crit_est_1),
  "Valeur critique r√©elle" = c(val_crit_10, val_crit_5, val_crit_1)
)

tableau_comparatif
```


Nous remarquons que les valeurs critiques estim√©es sont proches de celles de la table de Dickey-Fuller.

\newpage
## Processus avec constante delta_0 = 10

```{r}
set.seed(246)

# Param√®tres
nb_obs <- 100
nb_sim <- 10000

# Stockage des t-statistiques
t_stats <- numeric(nb_sim)

# Simulation du processus avec constante (delta_0 = 10)
delta_0 <- 10
for (i in 1:nb_sim) {
  
  epsilon <- rnorm(nb_obs, mean = 0, sd = 1)   # R√©sidus normaux centr√©s r√©duits
  Y <- numeric(nb_obs)
  
  Y[1] <- delta_0 + epsilon[1]  # Premi√®re observation avec constante
  
  for (t in 2:nb_obs) {
    Y[t] <- delta_0 + Y[t-1] + epsilon[t]  # Processus avec constante
  }
  
  # Cr√©ation de la variable de tendance
  trend <- 1:nb_obs  # Variable temporelle croissante
  
  # pour tester un mod√®le avec constante, il est pr√©f√©rable d‚Äôadopter une sp√©cification 
  # avec constante et tendance
  modele <- lm(Y[2:nb_obs] ~ Y[1:(nb_obs-1)] + trend[2:nb_obs])
  
  phi_1 <- coef(modele)[2]         # Coefficient estim√© phi_1 (sur Yt-1)
  gamma <- phi_1 - 1              # Calcul de gamma estim√©
  
  # Ecart-type de gamma (√©gal √† l'√©cart-type de phi_1)
  se_gamma <- summary(modele)$coefficients[2, 2]
  
  # Statistique de test
  t_stats[i] <- gamma / se_gamma
}

# Estimation de la densit√© par noyau pour visualiser la distribution
densite <- density(t_stats)

# Histogramme avec la courbe de densit√© liss√©e
hist(
  t_stats, 
  breaks = 50, 
  probability = TRUE, 
  col = "lightblue", 
  main = "Distribution des t-statistiques avec lissage par noyau", 
  xlab = "t-stat"
)
lines(
  densite,
  col = "red",
  lwd = 2
)

# Calcul des valeurs critiques pour 10%, 5% et 1%
val_crit_est_10 <- quantile(t_stats, 0.10)
val_crit_est_5  <- quantile(t_stats, 0.05)
val_crit_est_1  <- quantile(t_stats, 0.01)

cat("Valeur critique unilat√©rale √† 10% :", val_crit_est_10, "\n")
cat("Valeur critique unilat√©rale √† 5%  :", val_crit_est_5, "\n")
cat("Valeur critique unilat√©rale √† 1%  :", val_crit_est_1, "\n")

# Valeurs critiques r√©elles pour n = 100 et p = 10%, p = 5% et p = 1%
critical_values <- unitrootTable(trend = "ct", statistic = "t")

val_crit_10 <- critical_values["100", "0.100"]
val_crit_5  <- critical_values["100", "0.050"]
val_crit_1  <- critical_values["100", "0.010"]

# Tableau comparatif
tableau_comparatif <- tibble(
  "Seuil" = c("10%", "5%", "1%"),
  "Valeur critique estim√©e" = c(val_crit_est_10, val_crit_est_5, val_crit_est_1),
  "Valeur critique r√©elle" = c(val_crit_10, val_crit_5, val_crit_1)
)

tableau_comparatif
```

Nous remarquons que les valeurs critiques estim√©es sont proches de celles de la table de Dickey-Fuller.

La valeur de la constante dans les simulations n'a pas d'impact sur les r√©sultats du test. En comparant les valeurs critiques estim√©es pour $Œ¥_0 = 5$ et $Œ¥_0 = 10$, on observe qu'elles restent identiques et proches des valeurs critiques th√©oriques issues de la table de Dickey-Fuller. Cela confirme que la constante influence le niveau moyen du processus $Y_t$, mais n'affecte ni la statistique de test ni la significativit√© des r√©sultats.



\newpage
# Analyse de la s√©rie temporelle du PIB des USA sur la p√©riode 1990-2023

```{r, echo=FALSE}
load("data/GDP_US_1990_2023.RData")
```

## Visualisation de la s√©rie
```{r, echo=FALSE}
str(df_Y_us)
```

Il est important de v√©rifier que la Date est bien en format 'Date' !

```{r}
ggplot(df_Y_us, aes(x=Date, y=PIB)) +
  geom_line(color="blue", size=1) +
  labs(title="√âvolution du PIB des √âtats-Unis (1990-2024)",
       x="Ann√©e",
       y="PIB (en milliards de dollars)") +
  theme_minimal()
```

L'√©volution du PIB des √âtats-Unis n'a fait que d'augmenter depuis 1990, ce qui est caract√©ristique d'une tendance √† la hausse. On remarque √©galement quelques fortes baisses √† certaines p√©riodes. 
Aussi, d√ª au fort choc et arr√™t de la production en 2019 en raison de la crise COVID, on va restreindre la p√©riode √† 1990-2019.

\newpage
## 1. P√©riode de 1990 √† 2019

### 1. Mettre la s√©rie en time s√©rie et restreindre √† la p√©riode 1990-2019
```{r}
PIB_2019 <- ts(data = df_Y_us$PIB, start = c(1990, 1), end = c(2019, 1), frequency = 4)

plot(PIB_2019, main="Time-Series du PIB des USA sur la p√©riode 1990 √† 2019", col = "red")
```

La s√©rie temporelle met en √©vidence Un premier choc baissier visible en 2001, d√ª aux attentats du 11 septembre 2001. 
On remarque aussi la chute de la tendance haussi√®re du PIB des USA en 2008, d√ª √† la crise financi√®re et bancaire des subprimes. Ces chocs on eu un impacte significatif sur le PIB au USA.

\newpage
### 2. Zones ombr√©es pour les p√©riodes de r√©cession officielle aux US.
```{r}
# Jusqu'√† la p√©riode 2019
us_df_filtre <- df_Y_us |> 
  filter(Date <= as.Date("2019-01-01"))
```

```{r}
# Exemple des p√©riodes de r√©cession officielle aux US (source : NBER)
recessions <- data.frame(
  start = as.Date(c("1990-07-01", "2001-03-01", "2007-12-01")),
  end   = as.Date(c("1991-03-01", "2001-11-01", "2009-06-01"))
)

# Tracer le graphique avec zones de r√©cession
ggplot(us_df_filtre, aes(x = Date, y = PIB)) +
  # Ajout des zones de r√©cession
  geom_rect(data = recessions, 
            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
            fill = "orange", alpha = 0.3, inherit.aes = FALSE) +
  # Courbe du PIB
  geom_line(color = "blue", size = 1) +
  # Titres et labels
  labs(title = "√âvolution du PIB des √âtats-Unis (1990-2019)",
       x = "Ann√©e",
       y = "PIB (en milliards de dollars)") +
  # Th√®me √©pur√©
  theme_minimal()
```

Les zones ombr√©es montrent bien les diff√©rents points de r√©cessions officielle fourni par la National Bureau of Economic Research | NBER. La r√©cession la plus marquante fut celle de 2008, qui dura le plus longtemps. 


### 3. ACF et PACF de la s√©rie

```{r}
par(mfrow=c(1,2))
Acf(PIB_2019, main = "ACF du PIB des USA", col="lightblue", lwd = 4)
Pacf(PIB_2019, main = "PACF du PIB des USA", col="orange", lwd = 4)
par(mfrow=c(1,1))
```

La PACF montre que le PIB des USA d√©pend fortement du PIB de l'ann√©e pr√©c√©dente.
L'ACF montre une d√©croissance lente et progressive des autocorr√©lations, cette d√©croissance graduelle sans coupure nette est caract√©ristique d'un processus non-stationnaire. 

La s√©rie pr√©sente une forte tendance, ce qui est signe de non-stationnarit√©. Elle pr√©sente aussi une structure de d√©pendance o√π chaque observation est fortement li√©e aux observations pr√©c√©dentes et un comportement compatible avec un processus autor√©gressif d'ordre 1 (AR(1)) ou un mod√®le ARIMA avec composante int√©gr√©e. 


### 4. Proc√©dure de test de racine unitaire avec le test de Dickey-Fuller simple puis le test de Dickey-Fuller augment√©e.

On va ainsi chercher √† savoir si l'hypoth√®se nulle H0 (la s√©rie est non stationnaire, elle suit un processus de racine unitaire) est rejet√©e. 

La strat√©gie s√©quentielle pour le test de racine unitaire consiste √† :

1. Tester un mod√®le avec tendance et constante

2. Si on ne rejette pas H0 (pr√©sence de racine unitaire) ‚Üí Tester un mod√®le avec seulement une constante

3. Si on ne rejette toujours pas H0 ‚Üí Tester un mod√®le sans constante ni tendance

#### a). Test de Dickey-Fuller Simple (DF) avec approche s√©quentielle

Mod√®le avec tendance et constante :
```{r}
# Test de Dickey-Fuller simple
df_trend_const <- ur.df(PIB_2019, type = "trend", lags = 0)
summary(df_trend_const)
```

test-statistic = -1.2357 > tau3 pour 1%, 5%, et 10% donc on ne peut pas rejeter H0, alors on continue avec le mod√®le suivant. 

Mod√®le avec seulement une constante :
```{r}
df_const <- ur.df(PIB_2019, type = "drift", lags = 0)
summary(df_const)
```

test-statistic = 0.5628 > tau2 pour 1%, 5%, et 10% donc on ne peut pas rejeter H0, ce qui signifie que la racine unitaire est toujours pr√©sente, alors on continue avec le mod√®le suivant.

Mod√®le sans tendance ni constante :
```{r}
df_none <- ur.df(PIB_2019, type = "none", lags = 0)
summary(df_none)
```

Test-statistic > tau1, alors H0 est accept√©e ici, la s√©rie est non stationnaire, il faudra donc diff√©rencier la s√©rie.


#### b). Test de Dickey-Fuller Augment√© (ADF) avec approche s√©quentielle

Lorsque l'autocorr√©lation des r√©sidus est importante, on utilise l'ADF avec s√©lection automatique du lag optimal (g√©n√©ralement par le crit√®re AIC ou BIC).

Mod√®le avec tendance et constante :
```{r}
# Test de Dickey-Fuller augment√©
adf_trend_const <- ur.df(PIB_2019, type = "trend", selectlags = "AIC")
summary(adf_trend_const)
```

test-statistic : -1.7839 > tau3, donc H0 n'est pas rejet√©, alors alors on continue avec le mod√®le suivant.

Mod√®le avec seulement une constante :
```{r}
adf_const <- ur.df(PIB_2019, type = "drift", selectlags = "AIC")
summary(adf_const)
```

test-statistic : 0.1899 > tau2, donc H0 n'est pas rejet√©, alors alors on continue avec le mod√®le suivant

Mod√®le sans tendance ni constante :
```{r}
adf_none <- ur.df(PIB_2019, type = "none", selectlags = "AIC")
summary(adf_none)
```

Test-statistic > tau1, alors H0 est accept√©e ici, la s√©rie est non stationnaire, il faudra donc diff√©rencier la s√©rie.

Que ce soit pas la m√©thode Dickey-Fuller simple ou augment√©e, les test statistiques valident H0, alors la s√©rie du PIB est non stationnaire, il faudra diff√©rencier la s√©rie.


### 5. Appliquer le test de stationarit√©e de KPSS.

Hypoth√®se du test KPSS :

H‚ÇÄ (hypoth√®se nulle) : La s√©rie est stationnaire autour d'une moyenne ou d'une tendance lin√©aire.

H‚ÇÅ (hypoth√®se alternative) : La s√©rie est non-stationnaire.

```{r, message=FALSE, warning=FALSE}
kpss.test(PIB_2019)
```

p-value < 0.05, alors on rejette H0, la s√©rie est non-stationnaire, le test de KPSS donne un r√©sultat similaire aux test de Dickey-Fuller. 


\newpage
## 2. P√©riode de 1990 √† 2023

### 1. Mettre la s√©rie en time s√©rie et restreindre √† la p√©riode 1990-2023

```{r}
PIB_2023 <- ts(data = df_Y_us$PIB)
```


```{r}
# Tracer la s√©rie temporelle

plot(PIB_2023, main="Time-Series du PIB des USA sur la p√©riode 1990 √† 2023", col = "red")
```


### 2. Zones ombr√©es pour les p√©riodes de r√©cession officielle aux US (1990-2023)
```{r}
# P√©riodes de r√©cession officielle aux US de 1990 √† 2023

recessions <- data.frame(
  start = as.Date(c("1990-07-01", "2001-03-01", "2007-12-01", "2020-02-01")),
  end   = as.Date(c("1991-03-01", "2001-11-01", "2009-06-01", "2020-04-01"))
)


# Tracer le graphique avec zones de r√©cession
ggplot(df_Y_us, aes(x = Date, y = PIB)) +
  # Ajout des zones de r√©cession
  geom_rect(data = recessions, 
            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
            fill = "orange", alpha = 0.3, inherit.aes = FALSE) +
  # Courbe du PIB
  geom_line(color = "blue", size = 1) +
  # Titres et labels
  labs(title = "√âvolution du PIB des √âtats-Unis (1990-2023)",
       x = "Ann√©e",
       y = "PIB (en milliards de dollars)") +
  # Th√®me √©pur√©
  theme_minimal()
```

Les zones ombr√©es montrent bien les diff√©rents points de r√©cessions officielle fourni par la National Bureau of Economic Research | NBER. La r√©cession la plus marquante fut celle de 2008, qui dura le plus longtemps.

### 3. ACF et PACF de la s√©rie (avec la p√©riode 1990-2023)

```{r}
par(mfrow=c(1,2))
Acf(PIB_2023, main = "ACF du PIB des USA (2023)", col="lightblue", lwd = 4)
Pacf(PIB_2023, main = "PACF du PIB des USA (2023)", col="orange", lwd = 4)
par(mfrow=c(1,1))
```

La PACF montre que le PIB des USA d√©pend fortement du PIB de l'ann√©e pr√©c√©dente.
L'ACF montre une d√©croissance lente et progressive des autocorr√©lations, cette d√©croissance graduelle sans coupure nette est caract√©ristique d'un processus non-stationnaire. 

La s√©rie pr√©sente une forte tendance, ce qui est signe de non-stationnarit√©. Elle pr√©sente aussi une structure de d√©pendance o√π chaque observation est fortement li√©e aux observations pr√©c√©dentes et un comportement compatible avec un processus autor√©gressif d'ordre 1 (AR(1)) ou un mod√®le ARIMA avec composante int√©gr√©e.

Aucun retard significatif n'apparait en prenant en compte la p√©riode globale.


### 4. Proc√©dure de test de racine unitaire avec le test de Dickey-Fuller simple puis le test de Dickey-Fuller augment√©

#### a). Test de Dickey-Fuller Simple (DF) avec approche s√©quentielle

```{r}
# Mod√®le avec tendance et constante
df_trend_const_2023 <- ur.df(PIB_2023, type = "trend", lags = 0)
summary(df_trend_const_2023)
```

Comme la statistique du test de -2.5593 est sup√©rieure √† tau3 pour tous les niveaux de signification (1%, 5%, 10%), l'hypoth√®se nulle (H0 : s√©rie non stationnaire) n'est pas rejet√©e. La s√©rie est donc consid√©r√©e comme non stationnaire, et nous devons la diff√©rencier pour obtenir une stationnarit√©.


```{r}
# Mod√®le avec seulement une constante
df_const_2023 <- ur.df(PIB_2023, type = "drift", lags = 0)
summary(df_const_2023)
```

La statistique de 0.5829 est bien sup√©rieure aux valeurs critiques, et l'hypoth√®se nulle (pr√©sence de racine unitaire) ne peut pas √™tre rejet√©e. La s√©rie reste non stationnaire.


```{r}
# Mod√®le sans tendance ni constante
df_none_2023 <- ur.df(PIB_2023, type = "none", lags = 0)
summary(df_none_2023)
```

Le test-statistique de 5.3468 est bien sup√©rieur √† tau1, ce qui confirme que l'hypoth√®se nulle est valid√©e. La s√©rie est non stationnaire et n√©cessite une diff√©renciation.


#### b). Test de Dickey-Fuller Augment√© (ADF) avec approche s√©quentielle

```{r}
# Mod√®le avec tendance et constante
adf_trend_const_2023 <- ur.df(PIB_2023, type = "trend", selectlags = "AIC")
summary(adf_trend_const_2023)
```

La statistique de -2.0308 est inf√©rieure √† tau3 mais sup√©rieure √† tau1, ce qui indique que l'hypoth√®se nulle ne peut pas √™tre rejet√©e √† un niveau de signification de 1%. Cependant, la s√©rie reste non stationnaire.


```{r}
# Mod√®le avec seulement une constante
adf_const_2023 <- ur.df(PIB_2023, type = "drift", selectlags = "AIC")
summary(adf_const_2023)
```

La statistique de 0.7809 est bien sup√©rieure aux valeurs critiques pour tau2, et l'hypoth√®se nulle est accept√©e. La s√©rie est non stationnaire et devra √™tre diff√©renci√©e.


```{r}
# Mod√®le sans tendance ni constante
adf_none_2023 <- ur.df(PIB_2023, type = "none", selectlags = "AIC")
summary(adf_none_2023)
```

Le test-statistique de 5.8175 est bien sup√©rieur aux valeurs critiques pour tau1, ce qui confirme que l'hypoth√®se nulle de racine unitaire est valid√©e. La s√©rie est non stationnaire.


### 5. Appliquer le test de stationnarit√© de KPSS (pour la p√©riode 1990-2023)

```{r, message=FALSE, warning=FALSE}
# Test de KPSS
kpss.test(PIB_2023)
```

Le p-value est inf√©rieur √† 0.05, ce qui permet de rejeter l'hypoth√®se nulle (stationnarit√© autour de la moyenne ou d'une tendance lin√©aire). Cela confirme √©galement que la s√©rie est non stationnaire.

Les r√©sultats des tests de Dickey-Fuller et du test KPSS montrent que la s√©rie du PIB 2023 est non stationnaire. En effet, tant les tests DF que l'ADF n'ont pas permis de rejeter l'hypoth√®se nulle, et le test KPSS a √©galement rejet√© l'hypoth√®se de stationnarit√©. La s√©rie du PIB doit donc √™tre diff√©renci√©e pour obtenir une s√©rie stationnaire.

\newpage
## 3.Conclusion

Les conclusions principales concernant la non-stationnarit√© de la s√©rie du PIB des √âtats-Unis ne sont pas modifi√©es par l'extension de la p√©riode d'analyse de 1990 √† 2023. L'ajout de la crise de 2008 et de la r√©cession li√©e √† la pand√©mie de COVID-19 en 2020 renforce plut√¥t l'id√©e que la s√©rie du PIB pr√©sente des tendances non stationnaires sur une p√©riode plus longue, ce qui est confirm√© par tous les tests. La s√©rie du PIB reste fortement li√©e √† ses valeurs pass√©es, ce qui n√©cessite une diff√©renciation pour obtenir une stationnarit√©.

Ainsi, bien que les p√©riodes de r√©cession suppl√©mentaires apportent un contexte enrichi, la conclusion fondamentale ‚Äî que la s√©rie est non stationnaire et n√©cessite des ajustements ‚Äî reste inchang√©e.
